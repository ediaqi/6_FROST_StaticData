{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2539301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c246eb-df6d-4b1a-86d0-7c5fa1a40d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Observed properties.xlsx')\n",
    "df_csv_uom = df.to_csv('Observed properties.csv', index=False)\n",
    "df_csv_uom = pd.read_csv('Observed properties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a945833b-b8d6-469f-8e8f-62db345a3e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv_obs = pd.read_csv('Creazione_obs_property_....csv', sep=';')\n",
    "df_csv_obs\n",
    "#Observed property rispetto alla city o alla tipologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36b0e14-8097-4e4b-8e53-56d654c60d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('percorso_file.xlsx', sheet_name='Things')\n",
    "df_csv = df.to_csv('percorso_file.csv', index=False)\n",
    "df_csv = pd.read_csv('percorso_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5a681e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BATCH\n",
    "json_struct = []\n",
    "datastream_counter = #da valorizzare\n",
    "fixed_part = {\n",
    "    \"POST to\": \"v1.1/$batch\",\n",
    "    \"Headers\": \"Content-Type: application/json\",\n",
    "    \"requests\": []  \n",
    "}\n",
    "json_struct.append(fixed_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206b869a-c977-448c-bce3-58127bf25600",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_csv_obs, df_csv_uom, left_on='description', right_on='name ', how='inner')\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692b37f6-ce0e-468f-85ca-9b33b385ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_datastreams = []\n",
    "\n",
    "for i in range(1, 12): #change the range\n",
    "    #Lettura things precedentemente create\n",
    "    with open(f\"json\\\\thing_{i}.json\", \"r\") as json_file:\n",
    "        thing_data = json.load(json_file)\n",
    "        thing_id = thing_data[\"body\"][\"@iot.id\"]\n",
    "\n",
    "    for idx, loc_row in merged_df.iterrows():\n",
    "        iot_id_gen = f\"DST.FE.{datastream_counter:03}\"\n",
    "        json_data = {\n",
    "            \"id\": str(iot_id_gen),\n",
    "            \"method\": \"post\",\n",
    "            \"url\": \"Datastreams\",\n",
    "            \"body\": {\n",
    "                \n",
    "                \"Thing\": {\n",
    "                    \"@iot.id\": thing_id\n",
    "                },\n",
    "                \"Sensor\": {\n",
    "                    \"@iot.id\": \"SEN.\" # number of sensors\n",
    "                 },\n",
    "                \"ObservedProperty\": {\n",
    "                    \"@iot.id\": loc_row[\"id \"]\n",
    "                },\n",
    "                \"name\": f\"{loc_row['name']} ({loc_row['description_x']})@{thing_id}\",\n",
    "                \"description\": loc_row[\"description_x\"],\n",
    "                \"unitOfMeasurement\": {\n",
    "                    \"name\": loc_row[\"description uom\"],\n",
    "                    \"symbol\": loc_row[\"uom\"],\n",
    "                    \"definition\": loc_row[\"definition_x\"]\n",
    "                },\n",
    "                \"observationType\": \"OM_Measurement\",\n",
    "                \"properties\": {\n",
    "                    \"identifier\": str(iot_id_gen)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        if json_data not in added_datastreams:\n",
    "            json_struct[0][\"requests\"].append(json_data)\n",
    "            added_datastreams.append(json_data)\n",
    "        \n",
    "        datastream_counter += 1\n",
    "\n",
    "print(f\"Aggiunti {datastream_counter - 1} datastreams a json_struct.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab47a892-3908-4360-8f46-32bb215c563e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "formatted_json = json.dumps(json_struct, indent=3, ensure_ascii=False)\n",
    "\n",
    "try:\n",
    "    json.loads(formatted_json)\n",
    "    print(\"Il JSON Ã¨ stato formattato correttamente.\")\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Errore nella formattazione: {e}\")\n",
    "    \n",
    "with open('Datastreams.json', 'w', encoding='utf-8') as json_file:\n",
    "    json_file.write(formatted_json)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
